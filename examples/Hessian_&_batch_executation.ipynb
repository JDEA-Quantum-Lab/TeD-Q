{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7dc858",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hessian & batch executation\n",
    "\n",
    "This example shows how to obtan hessian and how to perform batch executation. Since functorch functions (vmap, hessian, jacfwd, etc.) currently do not support the use of autograd.Function. Hessian & batch executation function are only supported by PyTorch backend backpropagation autograd method now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496147a8",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2359d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tedq as qai\n",
    "import torch\n",
    "from functorch import hessian, jacfwd, vmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bda454",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define the quantum model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88114ab",
   "metadata": {},
   "source": [
    "### Define the circuit with TeD-Q framework\n",
    "#### (Remember, if you have multiple measurements, all the measurement results should has the same shape!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391463f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quantum circuit\n",
    "def circuitDef(params):\n",
    "    qai.RX(params[0], qubits=[0])\n",
    "    qai.RY(params[1], qubits=[0])\n",
    "    return qai.expval(qai.PauliZ(qubits=[0]))\n",
    "\n",
    "number_of_qubits = 1\n",
    "parameter_shapes = [(2,)]\n",
    "\n",
    "# Quantum circuit construction\n",
    "circuit = qai.Circuit(circuitDef, number_of_qubits, parameter_shapes = parameter_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb24529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the quantum circuit\n",
    "drawer = qai.matplotlib_drawer(circuit)\n",
    "drawer.draw_circuit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ff679",
   "metadata": {},
   "source": [
    "# Circuit compiled with pytorch backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14cac3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Gradient will obtain from backpropagation by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010154df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### state vector propagation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72fbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6051a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tensor network contraction mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be7e18",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Use CoTenGra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094402bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# slicing_opts = {'target_size': 2**28}\n",
    "# hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'progbar':True, 'minimize':'flops', 'parallel':True, 'slicing_opts':slicing_opts}\n",
    "# import cotengra as ctg\n",
    "# my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\", use_cotengra=ctg, hyper_opt = hyper_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba324828",
   "metadata": {},
   "source": [
    "#### Use JDtensorPath (Suggested)\n",
    "1. 'target_num_slices' is useful if you want to do the contraction in parallel, it will devide the tensor network into pieces and then calculat them in parallel\n",
    "2. 'math_repeats' means how many times are going to run JDtensorPath to find a best contraction path\n",
    "3. 'search_parallel' means to run the JDtensorPath in parallel, True means to use all the CPUs, integer number means to use that number of CPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f664e876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jdtensorpath import JDOptTN as jdopttn\n",
    "slicing_opts = {'target_size':2**28, 'repeats':500, 'target_num_slices':None, 'contract_parallel':False}\n",
    "hyper_opt = {'methods':['kahypar'], 'max_time':120, 'max_repeats':12, 'search_parallel':True, 'slicing_opts':slicing_opts}\n",
    "my_compilecircuit = circuit.compilecircuit(backend=\"pytorch\", use_jdopttn=jdopttn, hyper_opt = hyper_opt, tn_simplify = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd16662",
   "metadata": {},
   "source": [
    "### Define cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, weight):\n",
    "    results = my_compilecircuit(params)\n",
    "    return weight[0]*results + weight[1] + weight[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c183866",
   "metadata": {},
   "source": [
    "### Batch executation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94747b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First dimension is the batch size\n",
    "parameters = torch.rand((5, 2), requires_grad= True)\n",
    "weights = torch.rand((5, 3), requires_grad= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf4ee6-a923-4ea5-a715-89240d0db7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost(parameters[0], weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526e079-d186-4e09-80d2-6c478f9d224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch executation function\n",
    "vmap_cost = vmap(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20c1f0-7392-4e8d-a2d3-304f3bacb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap_cost(parameters, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a1000-be39-4a5c-879a-2e5a7e2b692b",
   "metadata": {},
   "source": [
    "### Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc97ad-68bf-4e70-8846-1497298c0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_cost = hessian(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8585a6-5f23-44d1-ab18-4814bfde006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hess = hess_cost(parameters[0], weights[0])\n",
    "hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695e577-918e-439a-bd69-ca8bf4103abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899f875-bbc5-469c-b9d8-a31a68507bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0d4dae2-f2b3-465f-9e20-57562aa7c55a",
   "metadata": {},
   "source": [
    "### Batch executation of hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1deb0-a766-4ba2-977a-35c34b75c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hess_cost = vmap(hess_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd922d-b3ce-4b24-ac33-873f7b3b9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hess_cost(parameters, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e57924-73e3-4802-a6ae-9955f4e37983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
